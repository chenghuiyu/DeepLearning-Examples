{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Convolutional Neural Network\n",
    "\n",
    "## Convolutional Network Framework\n",
    "\n",
    "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n",
    "\n",
    "## MNIST Dateset Overview\n",
    "\n",
    "This example is using MNIST handwritten digits. The dataset contains 60,000 examples for training and 10,000 examples for testing. The digits have been size-normalized and centered in a fixed-size image (28x28 pixels) with values from 0 to 1. For simplicity, each image has been flattened and converted to a 1-D numpy array of 784 features (28*28).\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "Done......!\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST dataset \n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "print (\"Done......!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization Parameters\n",
    "# hyper Params\n",
    "num_steps = 500\n",
    "learning_rate = 0.001\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 784 # MNIST input features (image shape: 28 * 28)\n",
    "num_classes = 10 # MNIST total classes (0 - 9 digits)\n",
    "dropout = 0.75 # Dropout, probability to keep units\n",
    "\n",
    "# tf input Graph\n",
    "X = tf.placeholder(tf.float32, shape = [None, num_input], name = 'X')\n",
    "Y = tf.placeholder(tf.float32, shape = [None, num_classes], name = 'Y')\n",
    "keep_prob = tf.placeholder(tf.float32, name = 'keep_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create some wrappers for simplicity\n",
    "def conv2d(x, W, b, strides = 1):\n",
    "    x = tf.nn.conv2d(x, W, strides = [1, strides, strides, 1], padding = 'SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "def maxpool2d(x, k = 2):\n",
    "    return tf.nn.max_pool(x, ksize = [1, k, k, 1], strides = [1, k, k, 1],\n",
    "                         padding = 'SAME')\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    \n",
    "    # MNISET input is a 1-D vector of 784 features(image shape: 28 * 28)\n",
    "    # reshape to match picture format [Height * Weight * channels]\n",
    "    # Tensor input become 4-D: [Batch size, Height, Weight, Channel]\n",
    "    x = tf.reshape(x, shape = [-1, 28, 28 ,1])\n",
    "    \n",
    "    # convolutional layer1\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # maxpooling 1\n",
    "    conv1 = maxpool2d(conv1, k = 2)\n",
    "    \n",
    "    # convolutinal layer2\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # maxpooling 2\n",
    "    conv2 = maxpool2d(conv2, k = 2)\n",
    "    \n",
    "    # fully connected layer\n",
    "    fc1 = tf.reshape(conv2, shape = [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    # apply dropout\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # output, class prediction\n",
    "    class_out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    \n",
    "    return class_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store weights ans biases in layers\n",
    "weights = {\n",
    "    # 5 * 5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5 * 5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7 * 7 * 64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class preduction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Construct CNN model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and opitimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = Y))\n",
    "opitimizer = tf.train.AdamOptimizer(learning_rate = learning_rate)\n",
    "train_op = opitimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, axis=1), tf.argmax(Y, axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variable\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1, Minibatch Loss = 48038.7773, Training accuracy = 0.070\n",
      "step : 10, Minibatch Loss = 25846.6016, Training accuracy = 0.305\n",
      "step : 20, Minibatch Loss = 9372.3301, Training accuracy = 0.531\n",
      "step : 30, Minibatch Loss = 4507.3320, Training accuracy = 0.734\n",
      "step : 40, Minibatch Loss = 5405.4043, Training accuracy = 0.742\n",
      "step : 50, Minibatch Loss = 2583.3276, Training accuracy = 0.836\n",
      "step : 60, Minibatch Loss = 3133.9741, Training accuracy = 0.844\n",
      "step : 70, Minibatch Loss = 3582.5566, Training accuracy = 0.820\n",
      "step : 80, Minibatch Loss = 2127.2993, Training accuracy = 0.859\n",
      "step : 90, Minibatch Loss = 2126.4131, Training accuracy = 0.883\n",
      "step : 100, Minibatch Loss = 2396.6968, Training accuracy = 0.875\n",
      "step : 110, Minibatch Loss = 5044.1992, Training accuracy = 0.844\n",
      "step : 120, Minibatch Loss = 1833.8031, Training accuracy = 0.836\n",
      "step : 130, Minibatch Loss = 938.8473, Training accuracy = 0.930\n",
      "step : 140, Minibatch Loss = 1424.1646, Training accuracy = 0.898\n",
      "step : 150, Minibatch Loss = 1747.9081, Training accuracy = 0.898\n",
      "step : 160, Minibatch Loss = 1086.9764, Training accuracy = 0.922\n",
      "step : 170, Minibatch Loss = 1234.6736, Training accuracy = 0.906\n",
      "step : 180, Minibatch Loss = 1871.5767, Training accuracy = 0.875\n",
      "step : 190, Minibatch Loss = 697.1698, Training accuracy = 0.922\n",
      "step : 200, Minibatch Loss = 2562.2500, Training accuracy = 0.875\n",
      "step : 210, Minibatch Loss = 759.5341, Training accuracy = 0.938\n",
      "step : 220, Minibatch Loss = 713.2534, Training accuracy = 0.953\n",
      "step : 230, Minibatch Loss = 1350.0349, Training accuracy = 0.922\n",
      "step : 240, Minibatch Loss = 1462.4150, Training accuracy = 0.891\n",
      "step : 250, Minibatch Loss = 1716.4850, Training accuracy = 0.875\n",
      "step : 260, Minibatch Loss = 1105.4385, Training accuracy = 0.930\n",
      "step : 270, Minibatch Loss = 1167.5062, Training accuracy = 0.930\n",
      "step : 280, Minibatch Loss = 2142.4609, Training accuracy = 0.906\n",
      "step : 290, Minibatch Loss = 1037.6635, Training accuracy = 0.922\n",
      "step : 300, Minibatch Loss = 718.8098, Training accuracy = 0.938\n",
      "step : 310, Minibatch Loss = 1334.1167, Training accuracy = 0.914\n",
      "step : 320, Minibatch Loss = 1359.1216, Training accuracy = 0.898\n",
      "step : 330, Minibatch Loss = 704.7115, Training accuracy = 0.945\n",
      "step : 340, Minibatch Loss = 879.8234, Training accuracy = 0.930\n",
      "step : 350, Minibatch Loss = 443.8434, Training accuracy = 0.961\n",
      "step : 360, Minibatch Loss = 1672.8599, Training accuracy = 0.906\n",
      "step : 370, Minibatch Loss = 1066.4879, Training accuracy = 0.938\n",
      "step : 380, Minibatch Loss = 594.2296, Training accuracy = 0.938\n",
      "step : 390, Minibatch Loss = 423.5006, Training accuracy = 0.977\n",
      "step : 400, Minibatch Loss = 696.6453, Training accuracy = 0.953\n",
      "step : 410, Minibatch Loss = 947.3859, Training accuracy = 0.914\n",
      "step : 420, Minibatch Loss = 563.7435, Training accuracy = 0.922\n",
      "step : 430, Minibatch Loss = 424.8596, Training accuracy = 0.953\n",
      "step : 440, Minibatch Loss = 221.5946, Training accuracy = 0.969\n",
      "step : 450, Minibatch Loss = 556.1327, Training accuracy = 0.953\n",
      "step : 460, Minibatch Loss = 869.0022, Training accuracy = 0.945\n",
      "step : 470, Minibatch Loss = 333.6489, Training accuracy = 0.969\n",
      "step : 480, Minibatch Loss = 366.2784, Training accuracy = 0.953\n",
      "step : 490, Minibatch Loss = 781.8326, Training accuracy = 0.945\n",
      "step : 500, Minibatch Loss = 558.3820, Training accuracy = 0.945\n",
      "optimizer finished\n",
      "Testing Accuracy:  0.371094\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(1, num_steps + 1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # Run Optimization op\n",
    "        # backprop\n",
    "        sess.run(train_op, \n",
    "                 feed_dict = {X: batch_x, \n",
    "                              Y: batch_y, \n",
    "                              keep_prob: dropout})\n",
    "        \n",
    "        if step % display_step == 0 or step == 1:\n",
    "            ls, acc = sess.run([loss_op, accuracy], \n",
    "                               feed_dict = {X: batch_x, \n",
    "                                            Y: batch_y, \n",
    "                                            keep_prob: 1.0})\n",
    "            \n",
    "            print (\"step : \" + str(step) + \", Minibatch Loss = \" + \\\n",
    "                  \"{:.4f}\".format(ls) + \", Training accuracy = \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "            \n",
    "    print(\"optimizer finished\")\n",
    "    \n",
    "    # Calculate accuracy for 254 MNISET test images\n",
    "    print (\"Testing Accuracy: \" ,\\\n",
    "          sess.run(accuracy, \n",
    "                   feed_dict = {X: mnist.test.images[:256], \n",
    "                                Y: mnist.test.labels[:256], \n",
    "                                keep_prob: 0.1}))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
